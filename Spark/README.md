# Spark

Podemos utilizar duas APIs de alto nível para manipular dados com o framework Spark:
- Spark com Python: pyspark
- Spark com SQL: Spark SQL

A primeira opção utiliza programação imperativa, enquanto a segunda utiliza programação declarativa.

Com um conjunto de dados foi demonstrado como um data wrangling pode ser realizado e então, responder algumas questões, utilizando cada uma das APIs. Lembrando que estes notebooks são para estudo e exemplificação de como utilizar o framework do Spark, uma vez que não se justifica adotar Spark para pequenos datasets.


### Instalar as depências necessárias para rodar os notebooks:
    `pip install findspark pyspark`
`
